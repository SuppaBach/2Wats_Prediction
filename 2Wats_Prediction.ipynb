{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2Wats_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPE3uC44a5ur8nsWs6B2G7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuppaBach/2Wats_Prediction/blob/master/2Wats_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuE2tDZNu5Ez",
        "colab_type": "text"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRH9uv0ApqAZ",
        "colab_type": "text"
      },
      "source": [
        "**Problem 3: The Tale of Two Wat** \n",
        "\n",
        "Chulalongkorn University's AI Academy 2020\n",
        "\n",
        "2nd round screening exam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSS8MT9mp8lX",
        "colab_type": "text"
      },
      "source": [
        "Candidate name : \n",
        "Suppawat Boonrach\n",
        "\n",
        "*   s.boonrach@outlook.com\n",
        "*   github.com/suppabach\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g0bY4lEqgaG",
        "colab_type": "text"
      },
      "source": [
        "There are three parts in this program\n",
        "\n",
        "1.   Preparation\n",
        "2.   Training\n",
        "3.   Prediction\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfs9m5S6WCGY",
        "colab_type": "text"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH4dApJ3XVS3",
        "colab_type": "text"
      },
      "source": [
        "Extract file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUWwu-k7WVk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/watprakeaw_vs_watpo.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJubO_I7W9jU",
        "colab_type": "text"
      },
      "source": [
        "Prepare directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jmcP9jMW_BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/watprakeaw_vs_watpo'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training WatPo pictures\n",
        "train_WatPo_dir = os.path.join(train_dir, 'WatPo')\n",
        "\n",
        "# Directory with our training WatPrakeaw pictures\n",
        "train_WatPrakeaw_dir = os.path.join(train_dir, 'WatPrakeaw')\n",
        "\n",
        "# Directory with our validation WatPo pictures\n",
        "validation_WatPo_dir = os.path.join(validation_dir, 'WatPo')\n",
        "\n",
        "# Directory with our validation WatPrakaew pictures\n",
        "validation_WatPrakeaw_dir = os.path.join(validation_dir, 'WatPrakeaw')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_afV2IYGXhq9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwkJzwb2XiLx",
        "colab_type": "code",
        "outputId": "8aa63674-1ae7-4e1a-8ed6-e2399a7f2451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_WatPo_fnames = os.listdir(train_WatPo_dir)\n",
        "print(train_WatPo_fnames[:10])\n",
        "\n",
        "train_WatPrakeaw_fnames = os.listdir(train_WatPrakeaw_dir)\n",
        "train_WatPrakeaw_fnames.sort()\n",
        "print(train_WatPrakeaw_fnames[:10])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['po1.png', 'po2.png', 'po3.png', 'po4.png']\n",
            "['prakeaw1.png', 'prakeaw2.png', 'prakeaw3.png', 'prakeaw4.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVYvdqI2XjM9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzSMxrDNXjiu",
        "colab_type": "code",
        "outputId": "663cf4d4-28b4-43ac-b23b-d055f5e0468a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print('total training WatPo images:', len(os.listdir(train_WatPo_dir)))\n",
        "print('total training WatPrakeaw images:', len(os.listdir(train_WatPrakeaw_dir)))\n",
        "print('total validation WatPo images:', len(os.listdir(validation_WatPo_dir)))\n",
        "print('total validation WatPrakeaw images:', len(os.listdir(validation_WatPrakeaw_dir)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training WatPo images: 4\n",
            "total training WatPrakeaw images: 4\n",
            "total validation WatPo images: 4\n",
            "total validation WatPrakeaw images: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAqiiKKIvGfe",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRdE5ImGhCSU",
        "colab_type": "code",
        "outputId": "de1f1614-ee4e-4b8f-adca-2ad53b82d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras import optimizers\n",
        "\n",
        "base_dir = '/tmp/watprakeaw_vs_watpo'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
        "datagen = ImageDataGenerator(rescale=1./255) # เราจะรีสเกลให้แคบลงเพื่อที่จะได้เรียนรู้เร็วขึ้น\n",
        "\n",
        "# automagically retrieve images and their classes for train and validation sets\n",
        "train_generator = datagen.flow_from_directory( # ตรงนี้จะสร้างออปเจ็คไว้เทรน\n",
        "        train_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=4,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = datagen.flow_from_directory( # ตรงนี้จะสร้างออปเจ็คไว้ validation\n",
        "        validation_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=4,\n",
        "        class_mode='binary')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_epoch = 4 #จำนวน epoch\n",
        "nb_train_samples = 4 #จำนวน sample ที่นำมาเทรน\n",
        "nb_validation_samples = 1 #จำนวน sample ที่นำมา validate\n",
        "\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        samples_per_epoch=nb_train_samples,\n",
        "        nb_epoch=nb_epoch,\n",
        "        validation_data=validation_generator,\n",
        "        nb_val_samples=nb_validation_samples)\n",
        "\n",
        "#สอนเสร็จก็เซฟ\n",
        "open(\"basic_cnn_20_epochs.h5\", \"wb\")\n",
        "model.save_weights('basic_cnn_20_epochs.h5')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8 images belonging to 2 classes.\n",
            "Found 8 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(512, 512,...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=1, epochs=4, validation_steps=1)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6842 - accuracy: 0.7500 - val_loss: 14.7628 - val_accuracy: 0.5000\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 2s 2s/step - loss: 31.4512 - accuracy: 0.2500 - val_loss: 9.4660 - val_accuracy: 0.5000\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.9690 - accuracy: 0.7500 - val_loss: 2.7692 - val_accuracy: 0.2500\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.3424 - accuracy: 0.2500 - val_loss: 4.9493 - val_accuracy: 0.2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49bwsg2OvS3R",
        "colab_type": "text"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUVotA7-q2CZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "470184f4-c5ef-485a-9eb9-c2f0f0d71e5d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras import optimizers\n",
        "import random\n",
        "\n",
        "img_width, img_height = 512, 512\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.load_weights('basic_cnn_20_epochs.h5')\n",
        "\n",
        "# Let's prepare a random input image of a cat or dog from the training set.\n",
        "WatPo_img_files = [os.path.join(train_cats_dir, f) for f in train_WatPo_fnames]\n",
        "WatPrakeaw_img_files = [os.path.join(train_dogs_dir, f) for f in train_WatPrakeaw_fnames]\n",
        "img_path = random.choice(WatPo_img_files + WatPrakeaw_img_files)\n",
        "\n",
        "predictg = img_to_array(load_img(img_path)\n",
        "prediction = model.predict_classes(predictg)\n",
        "if prediction[0][0] == 1: print(\"WatPo\")\n",
        "else : print(\"WatPrakeaw\")\n",
        " \n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-b073364a24b2>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    prediction = model.predict_classes(predictg)\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}